# Cumulative for the  Hadoop vs Spark
<details><summary>Prerequisites and Learning Objectives</summary>

## Prerequisites

- Basic knowledge in Hadoop Ecosystem, Python Programming language and Data Frame API.

## Learning Objectives

- After completing this module, anyone can be able to understand the difference between Hadoop and Spark.


</details>
<details><summary>Description</summary>

## Description

## Speed 

- Apache spark - Spark is a cluster computing technology developed by Apache. Compared to Hadoop, Apache Spark can run applications up to 100 times faster in memory and 10 times quicker on storage. Spark makes it possible by minimizing the number of reading/writing cycles to disk and storing intermediate data in memory.

- Hadoop MapReduce - As MapReduce reads and writes data to and from the disc, processing performance is slowed.

## Difficulty

- Apache Spark - RDD, or Resilient Distributed Dataset, allows Spark to have a large number of high-level operators, making it simple to programme.

- Hadoop MapReduce - Hadoop MapReduce - Every operation in MapReduce must be manually coded, which makes it extremely challenging to use.

## latency

- Apache Spark – It provides low-latency computing.
  
- Hadoop MapReduce – It is a high latency computing framework.

## Interactive mode

- Apache Spark – It can process data interactively.
  
- Hadoop MapReduce – It doesn’t have an interactive mode.

## Streaming

- Apache Spark – It will process real-time data through Spark Streaming.
  
- Hadoop MapReduce – With MapReduce, we can only process data in batch mode.

## Category

- Apache Spark – It is data analytics engine.
  
- Hadoop MapReduce – MapReduce is basic data processing engine.

## Language Developed

- Apache Spark – It is developed in Scala.
  
- Hadoop MapReduce – It is developed in Java language.

## Latency

- Apache spark - It provides low-latency computing.

- Hadoop MapReduce - It provides high latency computing.

</br>

|     **Factors**    |                      **Hadoop**                      |                                **Spark**                                |
|:------------------:|:-------------------------------------------------------:|:-----------------------------------------------------------------------:|
| _Ease of Use_      | It is difficult to use with no Interactive mode               | Easy to Use and supports interactive mode                               |
| _Data processing_  | Data Processing is ideal for batch processing           | Can handle all data processing requirements (batch, graph etc.)         |
| _Performance_      | Faster than traditional system                          | Runs 100 times faster in-memory and 10 times faster on disk than Hadoop |
| _Failure Recovery_ | Resume where it left off when it restarts               | start all over from beginning when it restarts                          |
| _Security_         | More secure as it uses all Hadoop security capabilities | less secure as the security is set to "OFF" by default                  |
| _Cost_             | MapReduce is a cheaper option in terms of cost.         | expensive due to its in-memory processing power and RAM requirement     |
| _Scheduler_        | Dependent on external job scheduler like Oozie          | can schedule all its tasks by itself                                    |



</details>
<details><summary>Real World Application</summary>

## Real World Example

## Hadoop

- Big Companies like Google, Oracle and Facebook are following the hadoop architecture and using it's Map reduce component for the processing of huge volume of data. 

- Marks and Spencer, one of the luxury brands, are using Hadoop's HDFS for maintaing and storing customer related data that helps them to do analytics on it to make decisions which targets the customers on the large scale. 

## Spark

- Santa Monica, California-based VideoAmp are using Spark. For real-time bid optimization and real-time analytics, Spark has been deployed in production since day one. Additionally, audience segmentation, forecasting, and user data modelling are all dependent on machine learning. Also for querying and ELT.
</details>
<details><summary>Implementation</summary> 

</details>
<details><summary>Summary</summary> 

## Summary

- In the above module we have learned some difference between Hadoop and Apache spark.

## Difficulty

- Apache Spark - RDD, or Resilient Distributed Dataset, allows Spark to have a large number of high-level operators, making it simple to programme.

- Hadoop MapReduce - Hadoop MapReduce - Every operation in MapReduce must be manually coded, which makes it extremely challenging to use.

## Latency

- Apache spark - It provides low-latency computing.

- Hadoop MapReduce - It provides high latency computing.

</br>

|     **Factors**    |                      **Hadoop**                      |                                **Spark**                                |
|:------------------:|:-------------------------------------------------------:|:-----------------------------------------------------------------------:|
| _Ease of Use_      | It is difficult to use with no Interactive mode               | Easy to Use and supports interactive mode                               |
| _Data processing_  | Data Processing is ideal for batch processing           | Can handle all data processing requirements (batch, graph etc.)         |
| _Performance_      | Faster than traditional system                          | Runs 100 times faster in-memory and 10 times faster on disk than Hadoop |
| _Failure Recovery_ | Resume where it left off when it restarts               | start all over from beginning when it restarts                          |
| _Security_         | More secure as it uses all Hadoop security capabilities | less secure as the security is set to "OFF" by default                  |
| _Cost_             | MapReduce is a cheaper option in terms of cost.         | expensive due to its in-memory processing power and RAM requirement     |
| _Scheduler_        | Dependent on external job scheduler like Oozie          | can schedule all its tasks by itself                                    |



</details>
<details><summary>Practice Questions</summary>

[Practice Questions](./Quiz.gift)</details>
